# Hands-on reinforcement learning

## Project 1: Tic-tac-toe!

#### Table of Contents  

- [00 - Why tic-tac-toe?](#0.-why-tic-tac-toe)
- [01 - Setup](#setup)
- [02 - What is Q-learning?](#q-learning)
- [03 - Let's solve the game with Q-learning! (solution 1)]()
- [04 - Test our solution works]()
- [05 - Faster learning with epsilon schedules]()
- [06 - Faster learning with double Q-learning]()
- [07 - Going deeper]()
- [08 - References]()


## 00 Why Tic-tac-toe?

We want to start with a simple game, for which we already know how to play optimally.
If you don't know the optimal strategy at this came, go check [this]().

The main point here is to prove how an agent can learn how to play optimally without
being explicitly told how.

We are going to use the reinforcement learning framework and algorithms
to come up with a learning agent, that improves with experience and eventually becomes
unbeatable at this game.

All the concepts and code we build for this "easy" game, will be the backbone of later
harder projects.


## 01 Setup



## 08 References

- https://www.youtube.com/watch?v=4C133ilFm3Q


- https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/
- https://www.rd.com/article/how-to-win-tic-tac-toe/

# TODOs

- [x] Implement `q_agent.py` code from this [colab](https://colab.research.google.com/drive/1w3RYXZ_tg80qNDQZf1I2KyZcigwz8Not?usp=sharing#scrollTo=eYGU9K7s1FiQ)
    - Try to speed up convergence --> maybe epsilon is decreasing too fast in this colab?
- [ ] Quickly scan [this video](https://www.youtube.com/watch?v=4C133ilFm3Q)





